{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6711d228",
   "metadata": {},
   "source": [
    "## CLIP avec un classifieur basé sur la forêt aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69de2f5900d2fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:35:34.582988Z",
     "start_time": "2025-03-27T16:35:18.970401Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5a7645904d6c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:35:34.649039Z",
     "start_time": "2025-03-27T16:35:34.602437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des labels dans le dataset d'entraînement :\n",
      " label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "train_df = pd.read_csv(\"../preprocessing_for_CLIP/train.csv\")\n",
    "test_texts_df = pd.read_csv(\"../preprocessing_for_CLIP/test_texts.csv\")\n",
    "test_labels_df = pd.read_csv(\"../preprocessing_for_CLIP/test_labels.csv\")\n",
    "train_folder_path = \"../dataset/TRAINING\"\n",
    "test_folder_path = \"../dataset/test\"\n",
    "\n",
    "print(\"Répartition des labels dans le dataset d'entraînement :\\n\", train_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fd8d7cfaecaa0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:36:37.580490Z",
     "start_time": "2025-03-27T16:36:35.121092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle CLIP...\n",
      "Modèle CLIP chargé !\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle CLIP et le processor pour prétraiter les images et textes\n",
    "print(\"Chargement du modèle CLIP...\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "print(\"Modèle CLIP chargé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48c7f9d4d837f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:51:33.106511Z",
     "start_time": "2025-03-27T16:51:33.097189Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_path_to_tensor(image_path, folder_path):\n",
    "    # Charger l'image avec PIL\n",
    "    full_image_path = os.path.join(folder_path, image_path)\n",
    "    image = Image.open(full_image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image, dtype=np.float32) / 255.0 \n",
    "\n",
    "    # Vérifier si les valeurs sont bien dans la plage [0, 1]\n",
    "    if np.any(image_np < 0) or np.any(image_np > 1):\n",
    "        print(f\"Attention: image avec valeurs hors de la plage [0, 1] dans {image_path}\")\n",
    "\n",
    "    # Utiliser le preprocesseur CLIP pour transformer l'image\n",
    "    inputs = processor(images=image, return_tensors=\"pt\", padding=True, do_rescale=False)\n",
    "\n",
    "    return inputs['pixel_values'][0]\n",
    "\n",
    "def get_clip_embeddings(texts, images):\n",
    "    # Prétraiter les textes séparément\n",
    "    text_inputs = processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "    \n",
    "    # Normaliser les images dans la plage [0, 1]\n",
    "    images_normalized = []\n",
    "    for image in images:\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = np.clip(image / 255.0, 0.0, 1.0)\n",
    "        else:\n",
    "            image = np.clip(np.array(image) / 255.0, 0.0, 1.0)\n",
    "        images_normalized.append(image)\n",
    "\n",
    "    # Prétraiter les images séparément\n",
    "    image_inputs = processor(images=images_normalized, return_tensors=\"pt\", padding=True, do_rescale=False)  # Désactiver la mise à l'échelle\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Obtenir les embeddings des textes et des images\n",
    "        text_embeds = model.get_text_features(**text_inputs)\n",
    "        image_embeds = model.get_image_features(**image_inputs)\n",
    "\n",
    "    return text_embeds, image_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29488d171c478581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:37:02.815372Z",
     "start_time": "2025-03-27T16:37:02.809737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset pour charger les textes et les images\n",
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, texts, images, labels):\n",
    "        self.texts = texts\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10913d4d451487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:40:58.052585Z",
     "start_time": "2025-03-27T16:37:03.411341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des images de train\n",
      "Chargement des images de test\n"
     ]
    }
   ],
   "source": [
    "# Charger les images\n",
    "print(\"Chargement des images de train\")\n",
    "train_images = [image_path_to_tensor(image_path, train_folder_path) for image_path in train_df[\"file_name\"]]\n",
    "print(\"Chargement des images de test\")\n",
    "test_images = [image_path_to_tensor(image_path, test_folder_path) for image_path in test_texts_df[\"file_name\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ae358382d55bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:41:22.795523Z",
     "start_time": "2025-03-27T16:41:22.784651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des datasets...\n"
     ]
    }
   ],
   "source": [
    "# Préparer les datasets\n",
    "print(\"Préparation des datasets...\")\n",
    "train_texts = train_df[\"text\"].tolist()\n",
    "train_labels = train_df[\"label\"].tolist()\n",
    "\n",
    "test_texts = test_texts_df[\"text\"].tolist()\n",
    "test_labels = test_labels_df[\"label\"].tolist()\n",
    "\n",
    "train_dataset = MemeDataset(train_texts, train_images, train_labels)\n",
    "test_dataset = MemeDataset(test_texts, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807a3d50f805e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:41:28.491875Z",
     "start_time": "2025-03-27T16:41:28.478853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des datasets terminée !\n",
      "Entraînement du modèle de random forest...\n",
      "Entraînement du modèle de random forest terminé !\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "print(\"Préparation des datasets terminée !\")\n",
    "\n",
    "print(\"Entraînement du modèle de random forest...\")\n",
    "\n",
    "# Entraîner un modèle de random forest sur les embeddings CLIP\n",
    "n_estimators = 50\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "min_samples_leaf = 4\n",
    "max_features = \"log2\"\n",
    "random_forest = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features, random_state=42)\n",
    "\n",
    "print(\"Entraînement du modèle de random forest terminé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9243f31978fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:41:30.016444Z",
     "start_time": "2025-03-27T16:41:30.009966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extraire les embeddings et entraîner le modèle\n",
    "def extract_embeddings(loader):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for texts, images, label in tqdm(loader, desc=\"Extraction des embeddings\", leave=False):\n",
    "        text_embeds, image_embeds = get_clip_embeddings(texts, images)\n",
    "        combined_embeds = torch.cat((text_embeds, image_embeds), dim=-1).numpy()\n",
    "        embeddings.append(combined_embeds)\n",
    "        labels.append(label.numpy())\n",
    "    return np.vstack(embeddings), np.hstack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1675fdfda4c33635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T17:13:42.771270Z",
     "start_time": "2025-03-27T16:52:43.406622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des embeddings sauvegardés...\n",
      "Chargement des embeddings terminé !\n"
     ]
    }
   ],
   "source": [
    "# Chemins des fichiers pour sauvegarder les embeddings\n",
    "train_embeddings_file = \"train_embeddings.npz\"\n",
    "test_embeddings_file = \"test_embeddings.npz\"\n",
    "\n",
    "# Vérifier si les fichiers existent déjà\n",
    "if os.path.exists(train_embeddings_file) and os.path.exists(test_embeddings_file):\n",
    "    print(\"Chargement des embeddings sauvegardés...\")\n",
    "    train_data = np.load(train_embeddings_file)\n",
    "    test_data = np.load(test_embeddings_file)\n",
    "    X_train, y_train = train_data[\"X\"], train_data[\"y\"]\n",
    "    X_test, y_test = test_data[\"X\"], test_data[\"y\"]\n",
    "    print(\"Chargement des embeddings terminé !\")\n",
    "else:\n",
    "    print(\"Extraction des embeddings d'entraînement...\")\n",
    "    X_train, y_train = extract_embeddings(train_loader)\n",
    "    print(\"Extraction des embeddings de test...\")\n",
    "    X_test, y_test = extract_embeddings(test_loader)\n",
    "    \n",
    "    print(\"Extraction des embeddings terminée !\")\n",
    "    \n",
    "    # Sauvegarde des embeddings\n",
    "    np.savez_compressed(train_embeddings_file, X=X_train, y=y_train)\n",
    "    np.savez_compressed(test_embeddings_file, X=X_test, y=y_test)\n",
    "    print(\"Embeddings sauvegardés !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368e3d00c6b781f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T17:42:19.761959Z",
     "start_time": "2025-03-27T17:42:16.274636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9678\n",
      "Test Accuracy: 0.664\n",
      "Train F1 Score: 0.9675337769711635\n",
      "Test F1 Score: 0.6983842010771992\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_train = random_forest.predict(X_train)\n",
    "y_pred_test = random_forest.predict(X_test)\n",
    "\n",
    "# Calculer les métriques\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_pred_train, average='binary')\n",
    "test_f1 = f1_score(y_test, y_pred_test, average='binary')\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Train F1 Score: {train_f1}\")\n",
    "print(f\"Test F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1211e61ce3abed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données exportées avec succès dans hyperparameters_results_rf.csv!\n"
     ]
    }
   ],
   "source": [
    "def format_dict(d):\n",
    "    return \" , \".join(f\"{int(k)} : {int(v)}\" for k, v in d.items())\n",
    "\n",
    "# Distribution des prédictions\n",
    "train_counts = Counter(y_pred_train)\n",
    "test_counts = Counter(y_pred_test)\n",
    "\n",
    "# Hyperparamètres et résultats\n",
    "params = {\n",
    "    \"batch_size\": 16,\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"max_features\": max_features,\n",
    "    \"train_acc\": round(train_acc, 4),\n",
    "    \"train_f1_score\": round(train_f1, 4),\n",
    "    \"test_acc\": round(test_acc, 4),\n",
    "    \"test_f1_score\": round(test_f1, 4)\n",
    "}\n",
    "\n",
    "output_file = \"hyperparameters_results_rf.csv\"\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    # Lire le fichier existant\n",
    "    with open(output_file, mode='r', newline='', encoding='utf-8-sig') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    header = rows[0]\n",
    "    existing_value_columns = [col for col in header[1:] if col.startswith(\"valeurs_\")]\n",
    "    if existing_value_columns:\n",
    "        last_index = max(int(col.split(\"_\")[1]) for col in existing_value_columns)\n",
    "        new_col_name = f\"valeurs_{last_index + 1}\"\n",
    "    else:\n",
    "        new_col_name = \"valeurs_1\"\n",
    "\n",
    "    header.append(new_col_name)\n",
    "\n",
    "    # Mettre à jour les lignes avec les nouvelles valeurs\n",
    "    for i in range(1, len(rows)):\n",
    "        key = rows[i][0]\n",
    "        if key in params:\n",
    "            rows[i].append(params[key])\n",
    "        else:\n",
    "            rows[i].append(\"\")\n",
    "\n",
    "    # Écrire les nouvelles données dans le fichier\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "else:\n",
    "    # Fichier n'existe pas encore, le créer et écrire les données\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Hyperparamètres et Résultats\", \"valeurs_1\"])\n",
    "\n",
    "        for key, value in params.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "print(f\"Données exportées avec succès dans {output_file}!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
