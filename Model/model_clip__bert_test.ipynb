{
 "cells": [
  {
   "cell_type": "code",
   "id": "e69de2f5900d2fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:57:10.670974Z",
     "start_time": "2025-04-03T17:56:56.345121Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model_clip_bert import MultimodalDataset, MultimodalClassifier, evaluate_model\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Developpement\\Cours\\IFT714-NLP\\Devoir2\\.venv\\ProjetMAMI\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "851e5326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:57:10.707808Z",
     "start_time": "2025-04-03T17:57:10.676984Z"
    }
   },
   "source": [
    "# 2. Vérification du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:57:10.998424Z",
     "start_time": "2025-04-03T17:57:10.994851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokeniser\n",
    "max_length = 128  # Longueur maximale des séquences tokenisées\n",
    "\n",
    "# Capacité du modèle\n",
    "batch_size = 16  # Taille des batchs\n",
    "num_epochs = 1\n",
    "\n",
    "# Paramètres du modèle\n",
    "dropout = 0.5  # Dropout\n",
    "learning_rate = 2e-5  # Taux d'apprentissage"
   ],
   "id": "b877a271dabe5920",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a9b5a7645904d6c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:57:13.061770Z",
     "start_time": "2025-04-03T17:57:11.006323Z"
    }
   },
   "source": [
    "# 3. Charger les données\n",
    "train_df = pd.read_csv(\"../preprocessing_for_CLIP/train.csv\")  # Doit contenir : file_name, text, label\n",
    "test_texts = pd.read_csv(\"../preprocessing_for_CLIP/test_texts.csv\")\n",
    "test_labels = pd.read_csv(\"../preprocessing_for_CLIP/test_labels.csv\")\n",
    "test_df = pd.merge(test_texts, test_labels, on=\"file_name\")\n",
    "\n",
    "# 4. Séparation train/val\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# 5. Créer les datasets\n",
    "train_dataset = MultimodalDataset(train_data, image_dir=\"../Dataset/TRAINING\", max_length=max_length)\n",
    "val_dataset = MultimodalDataset(val_data, image_dir=\"../Dataset/TRAINING\")\n",
    "test_dataset = MultimodalDataset(test_df, image_dir=\"../Dataset/test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "train_steps_per_epoch = len(train_loader)\n",
    "total_steps = num_epochs * train_steps_per_epoch"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "95fd8d7cfaecaa0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:57:14.952495Z",
     "start_time": "2025-04-03T17:57:13.073246Z"
    }
   },
   "source": [
    "# 6. Charger le modèle\n",
    "model = MultimodalClassifier().to(device)\n",
    "\n",
    "# 7. Définir l'optimizer et la loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = get_scheduler(\n",
    "    \"linear\",  # ou \"cosine\"\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7d48c7f9d4d837f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T18:06:20.910399Z",
     "start_time": "2025-04-03T17:57:14.964328Z"
    }
   },
   "source": [
    "# 8. Entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(\n",
    "            text_input_ids=batch[\"text_input_ids\"].to(device),\n",
    "            text_attention_mask=batch[\"text_attention_mask\"].to(device),\n",
    "            image_pixel_values=batch[\"image_pixel_values\"].to(device),\n",
    "        )\n",
    "        loss = criterion(logits, batch[\"label\"].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    val_acc, val_f1 = evaluate_model(model, val_loader, device)\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# 9. Test final\n",
    "test_acc, test_f1 = evaluate_model(model, test_loader, device)\n",
    "print(\"=== Test Results ===\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1 Score : {test_f1:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [04:01<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.4458\n",
      "Validation Accuracy: 0.8360, F1 Score: 0.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [04:20<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 0.2319\n",
      "Validation Accuracy: 0.8520, F1 Score: 0.8560\n",
      "=== Test Results ===\n",
      "Accuracy: 0.6850\n",
      "F1 Score : 0.7424\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T18:06:21.071638Z",
     "start_time": "2025-04-03T18:06:21.057513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. Export des données\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour formater les dictionnaires contenant des np.int64\n",
    "def format_dict(d):\n",
    "    return \" , \".join(f\"{int(k)} : {int(v)}\" for k, v in d.items())\n",
    "\n",
    "# Hyperparamètres et résultats\n",
    "params = {\n",
    "    \"max_length\": max_length,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"dropout\": dropout,\n",
    "    \"val_acc\": round(val_acc, 4),\n",
    "    \"val_f1_score\": round(val_f1, 4),\n",
    "    \"test_acc\": round(test_acc, 4),\n",
    "    \"test_f1_score\": round(test_f1, 4),\n",
    "}\n",
    "\n",
    "# Nom du fichier CSV\n",
    "output_file = \"BERT+CLIP_hyperparameters_results.csv\"\n",
    "\n",
    "# Vérifier si le fichier existe déjà\n",
    "if os.path.exists(output_file):\n",
    "    # Lire le fichier existant\n",
    "    with open(output_file, mode='r', newline='', encoding='utf-8-sig') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Déterminer le numéro de la prochaine colonne (valeurs_X)\n",
    "    header = rows[0]\n",
    "    existing_value_columns = [col for col in header[1:] if col.startswith(\"valeurs_\")]\n",
    "    if existing_value_columns:\n",
    "        last_index = max(int(col.split(\"_\")[1]) for col in existing_value_columns)\n",
    "        new_col_name = f\"valeurs_{last_index + 1}\"\n",
    "    else:\n",
    "        new_col_name = \"valeurs_1\"\n",
    "\n",
    "    # Ajouter le nom de la nouvelle colonne dans l'en-tête\n",
    "    header.append(new_col_name)\n",
    "\n",
    "    # Mettre à jour les lignes avec les nouvelles valeurs\n",
    "    for i in range(1, len(rows)):  # On commence à 1 pour ignorer l'en-tête\n",
    "        key = rows[i][0]\n",
    "        if key in params:\n",
    "            rows[i].append(params[key])  # Ajouter la valeur correspondante\n",
    "        else:\n",
    "            rows[i].append(\"\")  # Ajouter une cellule vide pour les lignes sans correspondance\n",
    "\n",
    "    # Écrire les nouvelles données dans le fichier\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "else:\n",
    "    # Fichier n'existe pas encore, le créer et écrire les données\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Écrire l'en-tête\n",
    "        writer.writerow([\"Hyperparamètres et Résultats\", \"valeurs_1\"])\n",
    "\n",
    "        # Écrire les valeurs\n",
    "        for key, value in params.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "print(f\"Données exportées avec succès dans {output_file}!\")"
   ],
   "id": "f3316702cb6e41b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données exportées avec succès dans BERT+CLIP_hyperparameters_results.csv!\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
