{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pré-traitement des données",
   "id": "307def314f776d8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classe et fonction pour charger les données",
   "id": "71e695915f8d281f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.652886Z",
     "start_time": "2025-03-14T17:32:57.642408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importer des bibliothèques\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Télécharger les ressources nécessaires\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fonction d'augmentation\n",
    "def remplacer_par_synonymes(phrase):\n",
    "    mots = nltk.word_tokenize(phrase)  # Tokenisation plus robuste avec NLTK\n",
    "    nouvelle_phrase = []\n",
    "\n",
    "    for mot in mots:\n",
    "        # Lemmatisation du mot\n",
    "        mot_lemme = lemmatizer.lemmatize(mot.lower())  # Lemmatisation et minuscule\n",
    "\n",
    "        # Ignorer les mots trop courants ou les prépositions sans synonymes pertinents\n",
    "        if mot_lemme in ['in', 'on', 'at', 'the', 'a', 'an', 'of', 'and', 'to']:\n",
    "            nouvelle_phrase.append(mot)  # Ne pas remplacer ces mots\n",
    "            continue\n",
    "\n",
    "        synsets = wn.synsets(mot_lemme, lang=\"eng\")  # Chercher les synonymes en anglais\n",
    "        if synsets:\n",
    "            # Prendre le premier synonyme si disponible\n",
    "            synonyme = synsets[0].lemmas(\"eng\")[0].name()\n",
    "            nouvelle_phrase.append(synonyme)\n",
    "        else:\n",
    "            nouvelle_phrase.append(mot)  # Si pas de synonyme, garder le mot original\n",
    "\n",
    "    return \" \".join(nouvelle_phrase)\n",
    "\n",
    "\n",
    "# Définir une classe pour stocker un seul exemple (instance) de sentiment (description, label)\n",
    "class MemeExample:\n",
    "    def __init__(self, label, description):\n",
    "        self.description = description\n",
    "        self.label = label\n",
    "\n",
    "        #print(description)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(repr(self.label) + \" : \" + self.description)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "\n",
    "# Lit les exemples de sentiments au format [0 ou 1]<TAB>[phrase brute] ; tokenise et nettoie les phrases.\n",
    "# Lire les exemples avec augmentation\n",
    "def read_meme_examples(infile, augment_data=False, augmentation_factor=1):\n",
    "    with open(infile, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter=\",\")\n",
    "        exs = []\n",
    "        for fields in reader:\n",
    "            label = 1 if \"1\" in fields[0] else 0\n",
    "            description = fields[1].lower()  # Convertir en minuscules\n",
    "\n",
    "            # Ajouter des copies augmentées avec des synonymes\n",
    "            for _ in range(augmentation_factor):\n",
    "                if augment_data:  # Si l'augmentation est activée\n",
    "                    exs.append(MemeExample(label, description))\n",
    "                    description_augmente = remplacer_par_synonymes(description)  # Appliquer l'augmentation\n",
    "                    exs.append(MemeExample(label, description_augmente))\n",
    "                else:\n",
    "                    exs.append(MemeExample(label, description))\n",
    "    return exs[1:]  # Ignorer la première ligne d'en-tête"
   ],
   "id": "7c53e18014a8744d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\enzoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\enzoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\enzoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### *Charger* les données",
   "id": "f382e0850faba4f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.692218Z",
     "start_time": "2025-03-14T17:32:57.687344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"# Monter le lecteur pour accéder aux fichiers dans gdrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\"\"\""
   ],
   "id": "3e24857778829696",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Monter le lecteur pour accéder aux fichiers dans gdrive\\nfrom google.colab import drive\\ndrive.mount('/content/gdrive', force_remount=True)\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.744610Z",
     "start_time": "2025-03-14T17:32:57.723738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#VOUS DEVEZ CHANGER LE CHEMIN DE train_file ET dev_file SELON OÙ VOUS LES STOCKEZ DANS VOTRE gdrive.\n",
    "\n",
    "\n",
    "data_path = \"../../preprocessing/\"\n",
    "\n",
    "#\"TODO\" changez le chemin pour train_file\n",
    "train_file = data_path + \"train.csv\"\n",
    "#\"TODO\" changez le chemin pour dev_file\n",
    "dev_file = data_path + \"test.csv\"\n",
    "\n",
    "# Charger les données des fichiers\n",
    "train_exs = read_meme_examples(train_file, False)\n",
    "dev_exs = read_meme_examples(dev_file, False)\n",
    "n_pos = 0\n",
    "n_neg = 0\n",
    "for ex in train_exs:\n",
    "    if ex.label == 1:\n",
    "        n_pos += 1\n",
    "    else:\n",
    "        n_neg += 1\n",
    "print(\"%d train examples: %d positive, %d negative\" % (len(train_exs), n_pos, n_neg))\n",
    "\n",
    "n_pos = 0\n",
    "n_neg = 0\n",
    "for ex in dev_exs:\n",
    "    if ex.label == 1:\n",
    "        n_pos += 1\n",
    "    else:\n",
    "        n_neg += 1\n",
    "print(\"%d dev examples: %d positive, %d negative\" % (len(dev_exs), n_pos, n_neg))\n",
    "\n",
    "for ex in train_exs[:10]:\n",
    "    print(ex)\n",
    "\n",
    "for ex in dev_exs[:10]:\n",
    "    print(ex)\n"
   ],
   "id": "4c51261db9472fdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 train examples: 5000 positive, 5000 negative\n",
      "1000 dev examples: 500 positive, 500 negative\n",
      "'0 : milk milkzip'\n",
      "'1 : roses are red violets are blue if you dont say yes ill just rape you quickmemecom'\n",
      "'0 : breaking news russia releases photo of donald trump with hooker in russian hotelwaitsorrywrong filenever mind'\n",
      "'0 : man seeking woman ignad 18 o'\n",
      "'0 : me explaining the deep lore of jrr tolkeins world of arda the prostitute i am paying to keep me company during covid quarantine 61'\n",
      "'0 : pictophle app straight white malle starts talking puts headphones in  ears feminism 1 reply swipe up to view 5 replies chat agtinkta mah wwiem 501 rated chats 2 mi away rate this chat today 1429 the headphones invented by a while male dont ever fucking talk to me you mean on this smartphone app that was created by a white man or on your phone in general that was created by a white man im gonna call the police if you dont stop harassing me oh ok you mean get a white male to come help you gif say something nice destruction 100 send'\n",
      "'0 : chinese restaurant faces closure after 30 years following complaints from leading judge 64 and wife over cooking smells wafting into their 525000 home they bought three years ago'\n",
      "'0 : you were the chosen one you were meant to destroy the downvoters not join them imgflipcom'\n",
      "'1 : 84 607 pm pull start for dishwasher 19 listed 22 hours ago send seller a message is this available send ifunnyco'\n",
      "'1 : scientists have discovered that there is intelligent dna in a lot of women unfortunately most of them spit it out ske a mo'\n",
      "'0 : facebook singles groups belike when a new woman joins the group imgflipcom'\n",
      "'1 : so if youre a feminist how can you eat dairy'\n",
      "'0 : when a cute girl left your message on seen'\n",
      "'1 : photographing something you want to show everyone object males woman it females'\n",
      "'0 : hey babe can you make me a sandwich hey babe can you make me a sandwich i should have bought the boat'\n",
      "'0 : me at 25 after a quick 5 mile run me at 35 after buckling my kid into the car seat'\n",
      "'1 : extreme rape the woman in this picture is going to get it very hard diydespaircom'\n",
      "'0 : when ur mom says you shouldnt waste the day watching netflix'\n",
      "'1 : women women women 0 respect'\n",
      "'1 : you rape her she knows she asked for it'\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Indexer les exemples\n",
    "Cette section contient le code d'un indexeur (Indexer) qui est utile pour créer un mappage entre les mots et les index. Il a déjà été implémenté pour vous. Lisez-le et essayez de comprendre ce que font ses méthodes."
   ],
   "id": "d31bbc11c4b46909"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.795796Z",
     "start_time": "2025-03-14T17:32:57.790686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bijection entre objets et entiers commençant à 0. Utile pour le mappage\n",
    "# étiquettes, attributs(features), etc. en coordonnées d'un espace vectoriel.\n",
    "\n",
    "# Cette classe crée un mapping entre des objets (ici des mots) et des index uniques\n",
    "# Par exemple : apple->1, banana->2, etc.\n",
    "\n",
    "class Indexer(object):\n",
    "    def __init__(self):\n",
    "        self.objs_to_ints = {}\n",
    "        self.ints_to_objs = {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str([str(self.get_object(i)) for i in range(0, len(self))])\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.objs_to_ints)\n",
    "\n",
    "    # Renvoie l'objet correspondant à l'index particulier\n",
    "    def get_object(self, index):\n",
    "        if (index not in self.ints_to_objs):\n",
    "            return None\n",
    "        else:\n",
    "            return self.ints_to_objs[index]\n",
    "\n",
    "    def contains(self, object):\n",
    "        return self.index_of(object) != -1\n",
    "\n",
    "    # Renvoie -1 si l'objet n'est pas présent, l'index sinon\n",
    "    def index_of(self, object):\n",
    "        if (object not in self.objs_to_ints):\n",
    "            return -1\n",
    "        else:\n",
    "            return self.objs_to_ints[object]\n",
    "\n",
    "    # Ajoute l'objet à l'index s'il n'est pas présent, renvoie toujours un index non négatif\n",
    "    def add_and_get_index(self, object, add=True):\n",
    "        if not add:\n",
    "            return self.index_of(object)\n",
    "        if (object not in self.objs_to_ints):\n",
    "            new_idx = len(self.objs_to_ints)\n",
    "            self.objs_to_ints[object] = new_idx\n",
    "            self.ints_to_objs[new_idx] = object\n",
    "        return self.objs_to_ints[object]"
   ],
   "id": "cbcdca6ffc5246f9",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Definir le modèle de régression logistique",
   "id": "6f494da5171b1524"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.825092Z",
     "start_time": "2025-03-14T17:32:57.822610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importer des bibliothèques\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import math"
   ],
   "id": "781b05318b0d55ea",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Definir l'extracteur d'attributs/features",
   "id": "6b68179bf72d7045"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.839976Z",
     "start_time": "2025-03-14T17:32:57.836290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Type de base d'extraction d'attributs (features). Prend un exemple et renvoie une liste indexée d'attributs.\n",
    "class FeatureExtractor(object):\n",
    "    # Extraire les attributs (features). Inclut un indicateur add_to_indexer pour contrôler si l'indexeur doit être étendu.\n",
    "    # Au moment du test, tous les attributs/features inconnus (non-vu auparavant) doivent être ignorés, mais au moment de l'entrainement,\n",
    "    # nous voulons probablement continuer à l'étendre.\n",
    "    def extract_features(self, ex, add_to_indexer):\n",
    "        raise Exception(\"Don't call me, call my subclasses\")\n",
    "\n",
    "\n",
    "# Extrait les attributs (features) unigramme sac-de-mots (BOW) d'une phrase.\n",
    "# Vous pouvez considérer un unigramme comme un mot unique (par exemple \"love\", \"you\").\n",
    "# C'est à vous de décider comment vous voulez gérer les comptages\n",
    "class UnigramFeatureExtractor(FeatureExtractor):\n",
    "    def __init__(self, indexer: Indexer):\n",
    "        self.indexer = indexer\n",
    "\n",
    "    def extract_features(self, ex, add_to_indexer=False):\n",
    "        features = Counter()\n",
    "        for w in ex.description.split(): # Tokenisation par mot plutôt que par caractère (sans le split)\n",
    "            feat_idx = self.indexer.add_and_get_index(w) \\\n",
    "                if add_to_indexer else self.indexer.index_of(w)\n",
    "            if feat_idx != -1:\n",
    "                features[feat_idx] += 1.0\n",
    "        return features"
   ],
   "id": "e92106c6cd649b14",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Definir les classifieurs de base",
   "id": "2ede55d02ebf2a1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.847733Z",
     "start_time": "2025-03-14T17:32:57.844963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Type de base du classificateur de sentiment\n",
    "class SentimentClassifier(object):\n",
    "    # faire une prédiction pour l'exemple donné\n",
    "    def predict(self, ex: MemeExample):\n",
    "        raise Exception(\"Don't call me, call my subclasses\")\n",
    "\n",
    "\n",
    "# Prédit toujours la classe positive\n",
    "class AlwaysPositiveClassifier(SentimentClassifier):\n",
    "    def predict(self, ex: MemeExample):\n",
    "        return 1"
   ],
   "id": "cd1a73c053dd3ca1",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classe régression logistique",
   "id": "887c03a0ccc241fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.858841Z",
     "start_time": "2025-03-14T17:32:57.853504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LogisticRegressionClassifier(SentimentClassifier):\n",
    "    def __init__(self, feat_extractor: FeatureExtractor, train_examples, num_iters=50, reg_lambda=0.0, learning_rate=0.1):\n",
    "        # TODO: Initialiser le modèle de régression logistique\n",
    "        \n",
    "        # Arguments : feat_extractor est unigram, train_examples est un jeu de données d'entrainement\n",
    "        # num_iters est le nombre d'époques, reg_lambda est le paramètre de régularisation\n",
    "        # learning_rate est le taux d'apprentissage utilisé dans la descente de gradient\n",
    "        \n",
    "        # ÉTAPE 1 : Définissez les variables pour les poids et les biais, et initialisez-les à zéro\n",
    "        \n",
    "        # ÉTAPE 2 : Appelez la fonction train(). (Cela a déjà été fait pour vous)\n",
    "\n",
    "        ##### DÉBUT DE LA SOLUTION #####\n",
    "        \n",
    "        \n",
    "        # Variable pour les poids\n",
    "        nb_features = len(feat_extractor.indexer)\n",
    "        self.weights = np.zeros(nb_features)\n",
    "        \n",
    "        # Variable pour le biais\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Permet d'utiliser le feature extractor dans la fonction predict \n",
    "        self.feat_extractor = feat_extractor\n",
    "        \n",
    "        ##### FIN DE LA SOLUTION  #####\n",
    "\n",
    "        self.train(feat_extractor, train_examples, num_iters, reg_lambda, learning_rate)\n",
    "\n",
    "\n",
    "    def train(self, feat_extractor: FeatureExtractor, train_examples, num_iters=50, reg_lambda=0.0, learning_rate=0.1, L2_regul=True):\n",
    "        # TODO : fonction d'entraînement du modèle de régression logistique.\n",
    "        # Utilisez une descente de gradient stochastique.\n",
    "\n",
    "        ##### DÉBUT DE LA SOLUTION #####\n",
    "\n",
    "        for epoch in range(num_iters):\n",
    "            for example in train_examples:\n",
    "                # Extraction des caracteristiques\n",
    "                features = feat_extractor.extract_features(example, add_to_indexer=False)\n",
    "\n",
    "                # Calcul de la sortie à l'aide du vecteur de poids, du biais ainsi que de la fonction d'activation (ici la fonction sigmoide)\n",
    "                z = sum(self.weights[index] * count for index, count in features.items()) + self.bias\n",
    "                p = 1 / (1 + np.exp(-z))\n",
    "\n",
    "                # Calcul de l'erreur (différence entre la prédiction et la cible)\n",
    "                error = example.label - p\n",
    "\n",
    "                # Mise à jour des poids avec l'erreur obtenue\n",
    "                for index, count in features.items():\n",
    "                    if L2_regul:\n",
    "                        self.weights[index] += error * count * learning_rate - (reg_lambda * self.weights[index])\n",
    "                    else:\n",
    "                        self.weights[index] += error * count * learning_rate\n",
    "\n",
    "\n",
    "                # Mise à jour du biais\n",
    "                self.bias += error * learning_rate\n",
    "\n",
    "\n",
    "        ##### FIN DE LA SOLUTION  #####    \n",
    "\n",
    "    def predict(self, example):\n",
    "        # TODO : prédiction du modèle de régression logistique pour un seul exemple\n",
    "        \n",
    "        ##### DÉBUT DE LA SOLUTION #####              \n",
    "\n",
    "        # Extraction des caracteristiques\n",
    "        features = self.feat_extractor.extract_features(example, add_to_indexer=False)\n",
    "\n",
    "        # Calcul de la sortie à l'aide du vecteur de poids, du biais ainsi que de la fonction d'activation (ici la fonction sigmoide)\n",
    "        z = sum(self.weights[index] * count for index, count in features.items()) + self.bias\n",
    "        p = 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        classe = 1 if p >= 0.5 else 0\n",
    "        \n",
    "        return classe\n",
    "        \n",
    "        ##### FIN DE LA SOLUTION  #####"
   ],
   "id": "8b33476e5a3f1ede",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Fonction d'entrainement pour la régression logisique",
   "id": "23d25b34f8931c01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.866885Z",
     "start_time": "2025-03-14T17:32:57.863247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entrainer un modèle de régression logsitique sur les exemples d'entrainement en utilisant le FeatureExtractor, tous donnés en paramètres.\n",
    "def train_lr(train_exs: List[MemeExample], feat_extractor: FeatureExtractor, reg_lambda) -> LogisticRegressionClassifier:\n",
    "    # TODO : fonction d'entraînement du modèle de régression logistique.\n",
    "    # Remplissez le feature_extractor.\n",
    "    # Initialisez et renvoiez un objet d'instance LogisticRegressionClassifier\n",
    "    \n",
    "    ##### DÉBUT DE LA SOLUTION #####\n",
    "    \n",
    "    # Remplissage du feature extractor\n",
    "    for example in train_exs:\n",
    "        feat_extractor.extract_features(example, add_to_indexer=True)\n",
    "    \n",
    "    # Instanciation du classifieur\n",
    "    classifier = LogisticRegressionClassifier(feat_extractor, train_exs, num_iters=50, reg_lambda=reg_lambda, learning_rate=0.1)\n",
    "    \n",
    "    return classifier\n",
    "    ##### FIN DE LA SOLUTION  #####"
   ],
   "id": "f45d95321606edad",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.875286Z",
     "start_time": "2025-03-14T17:32:57.872068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# POINT D'ENTREE PRINCIPAL pour vos modifications. \n",
    "# Entraîne et retourne un des modèles possibles selon les options passées.\n",
    "def train_model(feature_type, model_type, train_exs, reg_lambda=0.1):\n",
    "    \n",
    "    # Initialiser le feature extractor\n",
    "    if feature_type == \"unigram\":\n",
    "        feat_extractor = UnigramFeatureExtractor(Indexer())\n",
    "    else:\n",
    "        raise Exception(\"Pass unigram\")\n",
    "\n",
    "    # entrainer le modèle\n",
    "    if model_type == \"AlwaysPositive\":\n",
    "        model = AlwaysPositiveClassifier()\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        model = train_lr(train_exs, feat_extractor, reg_lambda=reg_lambda)\n",
    "    else:\n",
    "        raise Exception(\"Pass AlwaysPositive or LogisticRegression\")\n",
    "    return model"
   ],
   "id": "8ca6d398e07ac093",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fonctions pour l'évaluation du modèle",
   "id": "7aea25b23ef84aaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:32:57.893338Z",
     "start_time": "2025-03-14T17:32:57.888280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Évalue un classificateur donné sur les exemples donnés\n",
    "def evaluate(classifier, exs):\n",
    "    return print_evaluation([ex.label for ex in exs], [classifier.predict(ex) for ex in exs])\n",
    "\n",
    "\n",
    "# Imprime la précision en comparant la vérité du terrain (ground truth) - golds - et les prédictions, chacune étant une séquence d'étiquettes 0/1.\n",
    "def print_evaluation(golds, predictions):\n",
    "    num_correct = 0\n",
    "    num_pos_correct = 0\n",
    "    num_pred = 0\n",
    "    num_gold = 0\n",
    "    num_total = 0\n",
    "    if len(golds) != len(predictions):\n",
    "        raise Exception(\"Mismatched gold/pred lengths: %i / %i\" %\n",
    "                        (len(golds), len(predictions)))\n",
    "    for idx in range(0, len(golds)):\n",
    "        gold = golds[idx]\n",
    "        prediction = predictions[idx]\n",
    "        if prediction == gold:\n",
    "            num_correct += 1\n",
    "        if prediction == 1:\n",
    "            num_pred += 1\n",
    "        if gold == 1:\n",
    "            num_gold += 1\n",
    "        if prediction == 1 and gold == 1:\n",
    "            num_pos_correct += 1\n",
    "        num_total += 1\n",
    "\n",
    "    print(\"Accuracy: %i / %i = %.2f %%\" %\n",
    "          (num_correct, num_total,\n",
    "           num_correct * 100.0 / num_total))\n",
    "    return num_correct * 100.0 / num_total\n",
    "    \n",
    "# ENTRÉE PRINCIPALE POUR L'ÉVALUATION sur les jeux de données d'entrainement et de développement\n",
    "def eval_train_dev(model):\n",
    "    print(\"===== Train Accuracy =====\")\n",
    "    train_acc = evaluate(model, train_exs)\n",
    "    print(\"===== Dev Accuracy =====\")\n",
    "    eval_acc = evaluate(model, dev_exs)\n",
    "    return [train_acc, eval_acc]"
   ],
   "id": "51c923e5266ecb0c",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Évaluation du modèle avec une représentation unigramme Bag-of-Words",
   "id": "85482a5b8ac8d481"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:33:06.638134Z",
     "start_time": "2025-03-14T17:32:57.898325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entrainement du modèle\n",
    "lr_unigram_model = train_model('unigram', 'LogisticRegression', train_exs)"
   ],
   "id": "46190ec9964ad0fb",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:33:27.974448Z",
     "start_time": "2025-03-14T17:33:27.703373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"def print_predictions(classifier, exs):\n",
    "    for ex in exs:\n",
    "        print(f\"{ex.label} : {classifier.predict(ex)} : {ex.description}\")\n",
    "\n",
    "print_predictions(lr_unigram_model, dev_exs)\"\"\"\n",
    "\n",
    "def compute_prediction_distribution(classifier, exs, dataset_name=\"Dataset\"):\n",
    "    predictions = [classifier.predict(ex) for ex in exs]\n",
    "    num_zeros = sum(1 for p in predictions if p == 0)\n",
    "    num_ones = sum(1 for p in predictions if p == 1)\n",
    "\n",
    "    print(f\"=== Distribution des prédictions sur {dataset_name} ===\")\n",
    "    print(f\"Classe 0: {num_zeros} ({num_zeros / len(predictions) * 100:.2f}%)\")\n",
    "    print(f\"Classe 1: {num_ones} ({num_ones / len(predictions) * 100:.2f}%)\")\n",
    "    print(\"========================================\")\n",
    "\n",
    "# Calcul de la distribution des prédictions\n",
    "compute_prediction_distribution(lr_unigram_model, train_exs, \"Train\")\n",
    "compute_prediction_distribution(lr_unigram_model, dev_exs, \"Dev\")\n",
    "print()\n",
    "\n",
    "# Evaluation des prédictions\n",
    "accu = eval_train_dev(lr_unigram_model)"
   ],
   "id": "1f56c0cd2583badd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution des prédictions sur Train ===\n",
      "Classe 0: 7012 (70.12%)\n",
      "Classe 1: 2988 (29.88%)\n",
      "========================================\n",
      "=== Distribution des prédictions sur Dev ===\n",
      "Classe 0: 786 (78.60%)\n",
      "Classe 1: 214 (21.40%)\n",
      "========================================\n",
      "\n",
      "===== Train Accuracy =====\n",
      "Accuracy: 7924 / 10000 = 79.24 %\n",
      "===== Dev Accuracy =====\n",
      "Accuracy: 572 / 1000 = 57.20 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[79.24, 57.2]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T17:33:06.910133Z",
     "start_time": "2025-03-14T17:33:06.907076Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d9870bd764c474c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
