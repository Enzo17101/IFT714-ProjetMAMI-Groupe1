{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:11.700174Z",
     "start_time": "2025-03-14T20:49:11.695967Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pywin32_testutil import testmain\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import default_data_collator\n",
    "#from transformers.agents.evaluate_agent import classifier\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2b4b7416b781d",
   "metadata": {},
   "source": [
    "### Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b304cbad35c6635e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:11.711284Z",
     "start_time": "2025-03-14T20:49:11.707149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokeniser\n",
    "max_length = 128 # Longueur maximale des séquences tokenisées\n",
    "\n",
    "# Capacité du modèle\n",
    "batch_size = 16 # Taille des batchs\n",
    "num_epochs = 3 # Nombre d'époques\n",
    "\n",
    "# Dropout\n",
    "dropout_global = 0.4 # Dropout global\n",
    "dropout_attention = 0.4 # Dropout dans les couches d'attention\n",
    "\n",
    "# Autres paramètres du modèle\n",
    "#learning_rate = 2e-5 # Taux d'apprentissage\n",
    "weight_decay = 0.1 # Paramètre de régularisation L2\n",
    "warmup_steps = 0 # Pas de warmup\n",
    "load_best_model_at_end = True # Charger le meilleur modèle parmi ceux générés pendant les epochs\n",
    "\n",
    "# Nombre de labels dans le dataset\n",
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fbfcb274cd56db14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:11.740659Z",
     "start_time": "2025-03-14T20:49:11.736939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Détection du matériel à disposition pour l'entrainement du modèle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cpu = device.type == \"cpu\"\n",
    "\n",
    "if str(device) == \"cuda\":\n",
    "    device_name = torch.cuda.get_device_name()\n",
    "else:\n",
    "    device_name = \"CPU nul...\"\n",
    "\n",
    "print(\"Device:\", device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e948fe503c1dcf",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fbdb436e8c923848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:11.789097Z",
     "start_time": "2025-03-14T20:49:11.762739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des labels dans le dataset d'entraînement :\n",
      " label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Répartition des labels dans le dataset de test :\n",
      " label\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "train_df = pd.read_csv(\"../preprocessing/train.csv\")\n",
    "test_df = pd.read_csv(\"../preprocessing/test.csv\")\n",
    "\n",
    "# Nettoyage des données\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# Compter le nombre d'exemples dans chaque classe dans le dataset d'entraînement\n",
    "train_label_counts = train_df[\"label\"].value_counts()\n",
    "print(\"Répartition des labels dans le dataset d'entraînement :\\n\", train_label_counts)\n",
    "print()\n",
    "\n",
    "# Compter le nombre d'exemples dans chaque classe dans le dataset de test\n",
    "test_label_counts = test_df[\"label\"].value_counts()\n",
    "print(\"Répartition des labels dans le dataset de test :\\n\", test_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e4df0ccbc2b6177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:12.078538Z",
     "start_time": "2025-03-14T20:49:11.811478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizer de DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f2950f5954366f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:12.107055Z",
     "start_time": "2025-03-14T20:49:12.101136Z"
    }
   },
   "outputs": [],
   "source": [
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a2ffcb392be30",
   "metadata": {},
   "source": [
    "## Préparation et création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ed537a188a709ca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:12.733236Z",
     "start_time": "2025-03-14T20:49:12.131479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertConfig\n",
    "\n",
    "# Séparer 10-20% des données d'entraînement pour la validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df[\"text\"], train_df[\"label\"], test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Créer les datasets pour Trainer\n",
    "train_dataset = MemeDataset(train_texts.tolist(), train_labels.tolist())\n",
    "val_dataset = MemeDataset(val_texts.tolist(), val_labels.tolist())\n",
    "test_dataset = MemeDataset(test_df[\"text\"].tolist(), test_df[\"label\"].tolist())\n",
    "\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\")\n",
    "config.dropout = dropout_global  # Appliquer du dropout globalement\n",
    "config.attention_dropout = dropout_attention  # Appliquer du dropout dans les couches d'attention\n",
    "config.num_labels = num_labels  # Nombre de labels dans le dataset\n",
    "\n",
    "# Charger le modèle DistilBERT (sur le device détecté)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", config=config)\n",
    "_ = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4370951f614bd027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:12.815240Z",
     "start_time": "2025-03-14T20:49:12.754796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration de l'entraînement optimisée pour CPU\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=num_epochs,  # Réduire à 1 époque pour éviter un entraînement trop long\n",
    "    per_device_train_batch_size=batch_size,  # Réduire pour éviter saturation mémoire\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    use_cpu=use_cpu,\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=default_data_collator  # Ajout de cette ligne\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd5572f9962795",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fcd632931a879a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:52:24.029049Z",
     "start_time": "2025-03-14T20:49:12.837481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé sur NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Début de l'entrainement...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 03:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.552100</td>\n",
       "      <td>0.450651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.429497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.447493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1689, training_loss=0.451282060802724, metrics={'train_runtime': 191.0225, 'train_samples_per_second': 141.345, 'train_steps_per_second': 8.842, 'total_flos': 894154940928000.0, 'train_loss': 0.451282060802724, 'epoch': 3.0})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle (cela prendra du temps sur CPU)\n",
    "print(f\"Modèle chargé sur {device_name}\")\n",
    "print(\"Début de l'entrainement...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9cfb23c3b94e90e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:53:06.828804Z",
     "start_time": "2025-03-14T20:52:24.170608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution des prédictions sur TRAIN ===\n",
      "Classe 0: 4359 (48.43%)\n",
      "Classe 1: 4641 (51.57%)\n",
      "=================================\n",
      "=== Distribution des prédictions sur TEST ===\n",
      "Classe 0: 291 (29.10%)\n",
      "Classe 1: 709 (70.90%)\n",
      "=================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Train Accuracy =====\n",
      "Accuracy: 0.8547777777777777%\n",
      "F1 Score: 85.68%\n",
      "\n",
      "===== Dev Accuracy =====\n",
      "Accuracy: 63.1%\n",
      "F1 Score: 69.48%\n"
     ]
    }
   ],
   "source": [
    "# Obtenir les prédictions sur le train set\n",
    "predictions = trainer.predict(train_dataset)\n",
    "logits = predictions.predictions\n",
    "y_train = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Obtenir les prédictions sur le test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "logits = predictions.predictions\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Calculer la distribution des prédictions pour le train et le test\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "train_counts = dict(zip(unique_train, counts_train))\n",
    "\n",
    "unique_test, counts_test = np.unique(y_pred, return_counts=True)\n",
    "test_counts = dict(zip(unique_test, counts_test))\n",
    "\n",
    "# Afficher la distribution avec les pourcentages\n",
    "print(\"=== Distribution des prédictions sur TRAIN ===\")\n",
    "total_train = sum(counts_train)\n",
    "for label, count in train_counts.items():\n",
    "    percentage = (count / total_train) * 100\n",
    "    print(f\"Classe {label}: {count} ({percentage:.2f}%)\")\n",
    "print(\"=================================\")\n",
    "\n",
    "print(\"=== Distribution des prédictions sur TEST ===\")\n",
    "total_test = sum(counts_test)\n",
    "for label, count in test_counts.items():\n",
    "    percentage = (count / total_test) * 100\n",
    "    print(f\"Classe {label}: {count} ({percentage:.2f}%)\")\n",
    "print(\"=================================\")\n",
    "\n",
    "# Charger la métrique d'accuracy\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Obtenir les prédictions sur le train et dev set\n",
    "train_predictions = trainer.predict(train_dataset)\n",
    "train_logits = train_predictions.predictions\n",
    "train_labels = train_predictions.label_ids\n",
    "train_preds = np.argmax(train_logits, axis=-1)\n",
    "\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_logits = test_predictions.predictions\n",
    "test_labels = test_predictions.label_ids\n",
    "test_preds = np.argmax(test_logits, axis=-1)\n",
    "\n",
    "# Calculer l'accuracy\n",
    "train_acc = accuracy_metric.compute(predictions=train_preds, references=train_labels)['accuracy']\n",
    "test_acc = accuracy_metric.compute(predictions=test_preds, references=test_labels)['accuracy']\n",
    "\n",
    "# Calculer le F1 score\n",
    "train_f1 = f1_score(train_labels, train_preds, average='binary')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='binary')\n",
    "\n",
    "# Distribution des prédictions en pourcentage\n",
    "def distribution(y_pred):\n",
    "    unique, counts = np.unique(y_pred, return_counts=True)\n",
    "    total = len(y_pred)\n",
    "    distribution = {label: round((count / total) * 100, 2) for label, count in zip(unique, counts)}\n",
    "    return distribution\n",
    "\n",
    "train_dist = distribution(train_preds)\n",
    "dev_dist = distribution(test_preds)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"===== Train Accuracy =====\")\n",
    "acc = round(train_acc * 100, 2)\n",
    "print(f\"Accuracy: {train_acc}%\")\n",
    "\n",
    "acc = round(train_f1 * 100, 2)\n",
    "print(f\"F1 Score: {acc}%\")\n",
    "\n",
    "print(\"\\n===== Dev Accuracy =====\")\n",
    "acc = round(test_acc * 100, 2)\n",
    "print(f\"Accuracy: {acc}%\")\n",
    "\n",
    "acc = round(test_f1 * 100, 2)\n",
    "print(f\"F1 Score: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3559ece052302ef",
   "metadata": {},
   "source": [
    "## Export des résultats et hyperparamètres associés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6cfec8a177d6e047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:53:06.853721Z",
     "start_time": "2025-03-14T20:53:06.847741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données exportées avec succès dans hyperparameters_results.csv!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Hyperparamètres et résultats\n",
    "params = {\n",
    "    \"max_length\": max_length,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"dropout_global\": dropout_global,\n",
    "    \"dropout_attention\": dropout_attention,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"warmup_steps\": warmup_steps,\n",
    "    \"load_best_model_at_end\": load_best_model_at_end,\n",
    "    \"num_labels\": num_labels,\n",
    "    \"train_acc\": train_acc,\n",
    "    \"test_acc\": test_acc,\n",
    "    \"train_pred_distribution\": train_counts,\n",
    "    \"test_pred_distribution\": test_counts\n",
    "}\n",
    "\n",
    "# Nom du fichier CSV\n",
    "output_file = \"hyperparameters_results.csv\"\n",
    "\n",
    "# Écriture dans le CSV\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Écriture des hyperparamètres\n",
    "    writer.writerow([\"Hyperparamètres et Résultats\", \"Valeurs\"])\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, dict):\n",
    "            value = str(value)  # Convertir les distributions en string pour CSV\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "print(f\"Données exportées avec succès dans {output_file}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
