{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:41.884576Z",
     "start_time": "2025-03-14T20:18:41.880049Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pywin32_testutil import testmain\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import default_data_collator\n",
    "#from transformers.agents.evaluate_agent import classifier\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import f1_score\n"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparamètres",
   "id": "99c2b4b7416b781d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:41.902655Z",
     "start_time": "2025-03-14T20:18:41.898582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokeniser\n",
    "max_length = 128 # Longueur maximale des séquences tokenisées\n",
    "\n",
    "# Capacité du modèle\n",
    "batch_size = 16 # Taille des batchs\n",
    "num_epochs = 5 # Nombre d'époques\n",
    "\n",
    "# Dropout\n",
    "dropout_global = 0.2 # Dropout global\n",
    "dropout_attention = 0.4 # Dropout dans les couches d'attention\n",
    "\n",
    "# Autres paramètres du modèle\n",
    "#learning_rate = 2e-5 # Taux d'apprentissage\n",
    "weight_decay = 0.05 # Paramètre de régularisation L2\n",
    "warmup_steps = 0 # Pas de warmup\n",
    "load_best_model_at_end = True # Charger le meilleur modèle parmi ceux générés pendant les epochs\n",
    "\n",
    "# Nombre de labels dans le dataset\n",
    "num_labels = 2"
   ],
   "id": "b304cbad35c6635e",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:41.928462Z",
     "start_time": "2025-03-14T20:18:41.924614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Détection du matériel à disposition pour l'entrainement du modèle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cpu= True if device == \"cpu\" else False\n",
    "\n",
    "if str(device) == \"cuda\":\n",
    "    device_name = torch.cuda.get_device_name()\n",
    "else:\n",
    "    device_name = \"CPU nul...\"\n",
    "\n",
    "print(\"Device:\", device_name)"
   ],
   "id": "fbfcb274cd56db14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import des données",
   "id": "8e948fe503c1dcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:41.972810Z",
     "start_time": "2025-03-14T20:18:41.949793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Charger les données\n",
    "train_df = pd.read_csv(\"../preprocessing/train.csv\")\n",
    "test_df = pd.read_csv(\"../preprocessing/test.csv\")\n",
    "\n",
    "# Nettoyage des données\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# Compter le nombre d'exemples dans chaque classe dans le dataset d'entraînement\n",
    "train_label_counts = train_df[\"label\"].value_counts()\n",
    "print(\"Répartition des labels dans le dataset d'entraînement :\\n\", train_label_counts)\n",
    "print()\n",
    "\n",
    "# Compter le nombre d'exemples dans chaque classe dans le dataset de test\n",
    "test_label_counts = test_df[\"label\"].value_counts()\n",
    "print(\"Répartition des labels dans le dataset de test :\\n\", test_label_counts)\n"
   ],
   "id": "fbdb436e8c923848",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des labels dans le dataset d'entraînement :\n",
      " label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Répartition des labels dans le dataset de test :\n",
      " label\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:42.145360Z",
     "start_time": "2025-03-14T20:18:41.994592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenizer de DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "id": "5e4df0ccbc2b6177",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:42.171787Z",
     "start_time": "2025-03-14T20:18:42.166765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ],
   "id": "6f2950f5954366f9",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Préparation et création du modèle",
   "id": "f64a2ffcb392be30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:42.905610Z",
     "start_time": "2025-03-14T20:18:42.194115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DistilBertConfig\n",
    "\n",
    "# Préparer les datasets\n",
    "train_dataset = MemeDataset(train_df[\"text\"].tolist(), train_df[\"label\"].tolist())\n",
    "test_dataset = MemeDataset(test_df[\"text\"].tolist(), test_df[\"label\"].tolist())\n",
    "\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\")\n",
    "config.dropout = dropout_global  # Appliquer du dropout globalement\n",
    "config.attention_dropout = dropout_attention  # Appliquer du dropout dans les couches d'attention\n",
    "config.num_labels = num_labels  # Nombre de labels dans le dataset\n",
    "\n",
    "# Charger le modèle DistilBERT (sur le device détecté)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", config=config)\n",
    "_ = model.to(device)\n"
   ],
   "id": "ed537a188a709ca5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:18:43.005394Z",
     "start_time": "2025-03-14T20:18:42.927455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration de l'entraînement optimisée pour CPU\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=num_epochs,  # Réduire à 1 époque pour éviter un entraînement trop long\n",
    "    per_device_train_batch_size=batch_size,  # Réduire pour éviter saturation mémoire\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    use_cpu=use_cpu,\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=default_data_collator  # Ajout de cette ligne\n",
    ")"
   ],
   "id": "4370951f614bd027",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrainement du modèle",
   "id": "2edd5572f9962795"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-14T20:18:43.031941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entraînement du modèle (cela prendra du temps sur CPU)\n",
    "print(f\"Modèle chargé sur {device_name}... Début de l'entrainement...\")\n",
    "trainer.train()"
   ],
   "id": "fcd632931a879a10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé sur NVIDIA GeForce RTX 4060 Laptop GPU... Début de l'entrainement...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1537' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1537/3125 02:41 < 02:46, 9.52 it/s, Epoch 2.46/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.521600</td>\n",
       "      <td>0.770291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.746259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:17:42.756371Z",
     "start_time": "2025-03-14T20:17:00.104271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Obtenir les prédictions sur le train set\n",
    "predictions = trainer.predict(train_dataset)\n",
    "logits = predictions.predictions\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Calculer la distribution des prédictions\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "# Afficher la distribution avec les pourcentages\n",
    "total = sum(counts)\n",
    "print(\"=== Distribution des prédictions sur TRAIN ===\")\n",
    "for label, count in class_distribution.items():\n",
    "    percentage = (count / total) * 100\n",
    "    print(f\"Classe {label}: {count} ({percentage:.2f}%)\")\n",
    "print(\"=================================\")\n",
    "\n",
    "# Obtenir les prédictions sur le test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "logits = predictions.predictions\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Calculer la distribution des prédictions\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "# Afficher la distribution avec les pourcentages\n",
    "total = sum(counts)\n",
    "print(\"=== Distribution des prédictions sur TEST ===\")\n",
    "for label, count in class_distribution.items():\n",
    "    percentage = (count / total) * 100\n",
    "    print(f\"Classe {label}: {count} ({percentage:.2f}%)\")\n",
    "print(\"=================================\")\n",
    "\n",
    "\n",
    "\n",
    "# Charger la métrique d'accuracy\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Obtenir les prédictions sur le train et dev set\n",
    "train_predictions = trainer.predict(train_dataset)\n",
    "train_logits = train_predictions.predictions\n",
    "train_labels = train_predictions.label_ids\n",
    "train_preds = np.argmax(train_logits, axis=-1)\n",
    "\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_logits = test_predictions.predictions\n",
    "test_labels = test_predictions.label_ids\n",
    "test_preds = np.argmax(test_logits, axis=-1)\n",
    "\n",
    "# Calculer l'accuracy\n",
    "train_acc = accuracy_metric.compute(predictions=train_preds, references=train_labels)['accuracy']\n",
    "test_acc = accuracy_metric.compute(predictions=test_preds, references=test_labels)['accuracy']\n",
    "\n",
    "# Calculer le F1 score\n",
    "train_f1 = f1_score(train_labels, train_preds, average='binary')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='binary')\n",
    "\n",
    "# Distribution des prédictions en pourcentage\n",
    "def distribution(y_pred):\n",
    "    unique, counts = np.unique(y_pred, return_counts=True)\n",
    "    total = len(y_pred)\n",
    "    distribution = {label: round((count / total) * 100, 2) for label, count in zip(unique, counts)}\n",
    "    return distribution\n",
    "\n",
    "train_dist = distribution(train_preds)\n",
    "dev_dist = distribution(test_preds)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"===== Train Accuracy =====\")\n",
    "acc = round(train_acc * 100, 2)\n",
    "print(f\"Accuracy: {train_acc}%\")\n",
    "\n",
    "acc = round(train_f1 * 100, 2)\n",
    "print(f\"F1 Score: {acc}%\")\n",
    "\n",
    "print(\"\\n===== Dev Accuracy =====\")\n",
    "acc = round(test_acc * 100, 2)\n",
    "print(f\"Accuracy: {acc}%\")\n",
    "\n",
    "acc = round(test_f1 * 100, 2)\n",
    "print(f\"F1 Score: {acc}%\")"
   ],
   "id": "9cfb23c3b94e90e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution des prédictions sur TRAIN ===\n",
      "Classe 0: 5022 (50.22%)\n",
      "Classe 1: 4978 (49.78%)\n",
      "=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution des prédictions sur TEST ===\n",
      "Classe 0: 332 (33.20%)\n",
      "Classe 1: 668 (66.80%)\n",
      "=================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Train Accuracy =====\n",
      "Accuracy: 0.8354%\n",
      "F1 Score: 83.5%\n",
      "\n",
      "===== Dev Accuracy =====\n",
      "Accuracy: 64.2%\n",
      "F1 Score: 69.35%\n"
     ]
    }
   ],
   "execution_count": 68
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
